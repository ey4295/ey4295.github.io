---
layout:     post
title:      名词解释1
subtitle:   名词解释1
date:       2018-08-12
author:     徐清华
header-img: img/post-bg-ios9-web.jpg
catalog: 	 true
tags:
    - 自然语言处理
    - 名词解释
---

>本系列的文章将会对一些晦涩难懂的基本概念进行解释。文章侧重点在于使用通俗易懂，简明扼要的语言对这些概念进行说明。这么做的主要目标有两个：①加深对所解释的概念的理解；②提高语言组织，逻辑组织能力

![白井黑子](https://i.loli.net/2018/08/15/5b73ce4c672e4.png)

# 1.机器学习

#### 模型

&emsp;&emsp;机器学习官方定义呢是通过算法实现机器在某方面的表现的过程叫做机器学习。这个定义显然很好，很准确，但是却对初学者来说是非常非常没有意义的。

&emsp;&emsp;首先我们从一个最直观的角度来理解。相比你们也听说过，机器学习呢最终的目的就是为了预测。规范一点说就是通过从一堆数据中总结规律，我们可以对未知的情况发展做出预测。根据预测类型的不同呢，机器学习可以简单的分为**分类问题**和**回归问题**。而根据训练数据是否有标签可以分为**有监督**和**无监督**的训练。不同类型的问题呢，将会由不同的方案进行处理，但是我们需要注意的一点是：**无论什么类型的问题，其解决的方案只会从两个大方向出发：生成式和判别式模型**。

&emsp;&emsp;我们举一个简单的例子：红酒和白酒的判别。想象一下这样的场景：假如说你是一名鉴酒师。你的工作呢很简单，就是给你一瓶酒，你观察一下，喝一口，品一下（**特征提取**），然后给老板说这是白酒还是红酒（**预测**）。括号中加粗的两个名词呢就是你干的活了，简单吧。

&emsp;&emsp;现在呢，主要的问题就是怎么让电脑完成这一工作，怎么让电脑和你一样优秀？那么我们就得看看你的工作中比较难模仿的地方在哪里？没错，就是预测。你是凭借什么做出的预测呢？凭借你对酒的了解！你一生阅酒无数，从酒中总结出来了规律。这里我们需要说明一下，在这个世界上鉴酒师还有很多，他们也都总结出来了自己的规律，他们有的只是认识到了最表层的规律，有的则像你一样认识到了最深刻的规律。我们大概呢是可以将这世界上的品酒师分为两种：生成式鉴酒师和判别式鉴酒师。判别式鉴酒师比较菜，他们只会一件事：判别。顾名思义，只要给一瓶酒他们就能告诉你这是什么酒。而生成式鉴酒师可就厉害了，和酒相关的所有事情他都无所不知，无所不晓。无论是判别是什么酒，还是根据酒的类别说出酒的特点他们都能应对的游刃有余。

&emsp;&emsp;好啦，小故事到这里就要告一段落了，我们来看看这里的数学含义都是什么。我们首先给出几个基本概念。我们的鉴酒问题呢，本质上是个分类问题，假设我们从任意一瓶酒中提取出的信息为向量$x=(x_1,x_2,...,x_T)$,该向量包含$T$个特征（特征可以理解为属性，比如说纯度、颜色、甜度等）。那么老板给你的这瓶酒假如说是$x^{now}$，现在的问题就变成了预测酒的品种$y^{now}$。

&emsp;&emsp;判别式模型经过训练之后可以获得任意一瓶酒的条件概率$p(y|x)$，有了这个公式我们只需要把特征向量$x=x^{now}$代入，就能求出来每个类别对应的概率，那么概率最高的就是模型对这瓶酒的预测类别。即

$$y^{now}=arg max_{y \in Y} \{p(y|x=x^{now})\}$$

&emsp;&emsp;常见的判别式模型如下图

![常见判别式模型](https://i.loli.net/2018/08/15/5b73c2a98c198.png)

&emsp;&emsp;生成式模型经过训练之后可以获得酒和酒的品类的所有信息，也就是联合概率分布$p(x,y)$，那么这个时候要是想对问题进行预测的话就只需要利用**贝叶斯公式**，就可以在预测时转化成判别式模型一样的问题。（注意，在预测一个样本的归属时，$x$是固定不变的，所以分母是不变的，因此只要比较分子就可以，而分子就是生成式模型的基本公式，所以一定是已知的）


$$p(y|x)=\frac{p(x,y)}{p(x)}$$

&emsp;&emsp;常见的生成式模型如下图

![常见生成式模型](https://i.loli.net/2018/08/15/5b73c25c2d7c9.png)

&emsp;&emsp;讲到这里，我们不得不额外提到另外一种模型——生成函数模型。从前面的介绍中我们可以看出，生成式模型学的东西最多，判别式模型学的东西有所减少但是仍然足够用来做分类。并且无论是生成式还是判别式在做预测的时候都是通过比较各个分类标签的概率得到的最有可能的预测结果。而生成函数模型呢，则是采用了一种更加简洁明了的方式——直接对类别的分界线建模。我们想想一下，这样建立起来的模型，不可能对酒和类别标签的分布有着深入的认识，甚至说对酒本身的概率分布也是认识不足的，它能做的就是把酒分类，仅此而已。该模型的基本形式是

$$y=f(x)$$

#### 训练

&emsp;&emsp;前面介绍了三种基本模型，可以说有了这些模型我们就能做出预测了。但是问题就在于，这些模型怎么得到？其实确定这些模型，就是指的确定这些模型的参数，而确定模型参数就是利用手头上已经有的数据总结规律，选择最适合的一套参数，而这样的过程就是**模型的训练**。

&emsp;&emsp;模型的训练过程其实并不复杂，无论是判别式、生成式还是生成函数式，都会用一个式子来表示模型。

$$p(y|x)$$

$$p(x,y)$$

$$y=f(x)$$

&emsp;&emsp;可以说，无论是哪一种，我们采取的措施是一样的。

&emsp;&emsp;1.**做出假设**。简单来说，就是给模型一个具体的形式。比如说我们假设$y=f(x)=w_0+w_1x_1+w_2x_2+...+w_nx_n$

&emsp;&emsp;2.**搜索假设空间，选择最优参数**。想一想，我们要选择最优的参数，最简单的办法就是遍历参数空间里所有可能的组合。但是，我们也能看出这样做的代价太大。所以存在着一系列的方法能够帮助我们更快更高效的选择最适合的参数，而这些方法呢就是**优化方法**，包括梯度下降等各种方法。

#### 预测

&emsp;&emsp;有了训练好的模型，预测问题就变得水到渠成了。我们只需要把待预测的样本输入到模型当中，就能够根据不同的预测机制对该样本的结果进行预测。这里也就不再多说了。

---

# 神经网络

&emsp;&emsp;神经网络，英文全称是Atificial Neural Network，即人工神经网络。这个名字起的其实是不负责任的，因为两者之间千差万别。之所以叫这个名字是因为人工神经网络从人类神经网络中借鉴了一些观点，注意只是一些。

&emsp;&emsp;那么我们来看神经网络模型的提出。没错，我说是模型。神经网络就是前面提到的机器学习的模型部分替换成了神经网络。那么为什么要替换呢？答案很简单，就是原来的模型太简单，只能对简单的任务进行处理，遇到复杂的任务就麻了爪了。那么什么是简单什么是复杂呢？我们来看一下第一段中提出的一个例子。$y=f(x)=w_0+w_1x_1+w_2x_2+...+w_nx_n$。这个模型简单吧，可以说是简单到爆表，这个东西在高维空间上就是一个直线作为类别的分割线。换句话说，就是我们这个模型要想奏效，那么所有的数据必须在高维度空间上是可分的。下图就是一个二维的可视化例子。从图中我们能发现这种情况太齐整啦！我们的模型就是图中的这个直线，我们调整参数的过程就是调整这条直线的位置和斜率。但是怎么调节这个东西都是直来直去，永远是条直线。

![二维实例](https://i.loli.net/2018/08/15/5b73c8f945d7f.png)

&emsp;&emsp;因此我们考虑给这条直线增加一点可调节性，如果说我们不仅仅是可以调节这条直线的位置和斜率，还能调整它的弧度。那这样假设空间一下子扩大了，但是能够应对的情况就更加的丰富了。而要想增加对弧度的控制就需要增加高维度的东西。模型基本形式就可以修改成$y=f(x)=w_0+w_1x_1+w_2x_2+...+w_nx_n+u_1x_1^2+u_2x_2^2+...+u_nx_n^2$。观察下面的示意图，我们发现此时的这种分布，无论用什么直线都没有办法在这个维度上进行区分了。（**当然，一些降维啊什么的方法可能还是可以解决的，这里先不提**）只能采用的是能够调节曲线弧度的模型。再进一步，我们发现，这个参数越多啊，我们的模型的可调节性也就越大；但是同时，参数越多，训练的难度也就越大，这是一个需要平衡的问题，这也是后话了，在此不表。总结一下，**在一定程度上增加特征的高阶到模型中，有助于增加模型的有效性**。

![修改后的模型](https://i.loli.net/2018/08/15/5b73ca71c4707.png)

&emsp;&emsp;故事讲到这里，我们的神经网络就要隆重出场了。我们要知道，如果想要增加高阶的特征，可以手动的去设计，想怎么增加就怎么增加。但是也有一种比较好的增加方式，就是使用神经网络增加高阶的特征。神经网络中层的概念就是对前面的输入进行变化，这样的变换可以是线性的也可以是非线性的。其中非线性的变换呢就可以看做是增加了对弧度的控制等等。

# 深度学习

&emsp;&emsp;深度学习，一言以蔽之，就是多层的神经网络。其产生的主要原因就是人们在研究的过程中，发现使用多层的神经网络将会产生意外的好的效果。

# 自然语言处理

&emsp;&emsp;自然语言处理，是人工智能领域的一个重要的研究方向。简单来说就是想要**让计算机理解人类的语言。**这样一句话说出来，其实立马就有两个问题：什么是人类的语言？怎么才叫理解了人类的语言？任何一篇NLP领域的论文，其实都是在回答这样两个问题。

&emsp;&emsp;首先第一个问题，什么是人类的语言？这个问题不用说，你也最起码知道人类的语言是及其复杂的。形式多样，演变迅速等等特点使得人类的语言这一概念变得非常难以定义。但是有一点是没有错的，**即语言是一个有多种基本规则构成的复杂的复合体。**因此，所有的论文都是针对语言的某一个方面，做出一个基本假设，然后进行建模和分析。这样的假设包括“单词的含义可以从不同文章中出现的频率所确定”、“文章的含义可以从文章中单词的分布确定”、“翻译是根据原句的内容结合知识进行的解码过程”等等，这些假设有的已经过时，有的仍然炙手可热。

&emsp;&emsp;第二个问题，什么叫理解？正如前面所提到的，任何一篇论文都是从语言的而某一个方面出发进行研究。那么对应的理解这么一个概念就是完成不同的任务，比如预测下一个词能够预测的比较准；文章分类能够分的比较好等等。同时，我们需要知道，这些子任务整体都结合起来，完成的都比较好才能叫自然语言处理这个大任务我们已经完成了。

# 词向量（Embeddings）

&emsp;&emsp;词向量呢，简单来说就是使用一个向量来表示一个单词。其**基本假设呢，是说任何一个单词都是在空间中对应了一个一个点**。

&emsp;&emsp;我曾经在另外一篇文章中花了大力气介绍了一篇综述类的论文。在这里我也不想多费口舌了。词向量的发展主要是经历了“one-hot->document-based->hand-crafted feature vectors->word Embeddings->contextualized word Embeddings”这样一个过程。

# 指代消歧(Coreference Resolution)

&emsp;&emsp;指代消歧指的是确定文章中的两个名词短语是否指代的是同一个人、物、事等。其基本假设是：在一篇文章中，对同一个东西的指代可能有多种多样的形式，这些指代呈现出聚类的特征。举个例子来说,"张雪迎在电影狗13中表现很好。我很喜欢**她**的表演。"请问这里的她指的是谁？这就是指代消歧需要解决的问题。

&emsp;&emsp;指代消歧的基本解法有：`Mention-Pair`,`Mention-Rank`,`Mention-Tree`,`Entity-Mention`等。一个个的介绍，首先是`Mention-Pair`.这是目前研究最多的一种方案，其基本假设就是我们不去考虑这是个聚类的问题，我们只需要考虑一下从所有的`Mention`中拿出一对，判断这一对有没有是不是指代的同一个东西就好啦。这个问题就变成了分类问题。

&emsp;&emsp;`Mention-Rank`呢，就是从所有的`Mention`中选择一个，然后给剩下所有的`Mention`按照是否是指代同一个东西进行排序。这个问题就变成了排序问题。

&emsp;&emsp;`Mention-Tree`。就是把所有聚成一堆的指代当成一棵树，那么这个问题就变成了树的解析的问题。

&emsp;&emsp;`Mention-Entity`。就是认为所有的指代都是指向一个文本中没有出现过的实体，通过学习这个实体就可以完成指代消歧。这是最合理的一种假设，但是研究的人员并不算多。


# 结构化预测 (Structured Prediction)

&emsp;&emsp;结构化的预测这个概念呢，在论文中经常出现。其本意很简单，就是我们预测的最终的结果不再是一个简单的标签啦，而是一系列的标签（序列标注）或者一颗树（依赖解析）等等。

&emsp;&emsp;解决这种问题呢，最简单的做法是`Structured Perceptron`的算法。然后呢还有图模型的算法，还有呢就是结构拆开，一个个标签的去预测。都行，具体问题具体分析吧。


# 文本依赖解析（Discourse Parsing）

&emsp;&emsp;长文本的依赖是自然语言处理研究的一个重点任务。但是本质上呢还是一个依赖解析的问题。依赖解析问题的最常见处理方式有两大类：基于转移的（`Transition-Based`）和基于图的（`Graph-Based`）。前者就是一个改进版的贪心算法，通过`shift-reduce`的过程，扩大贪心的范围。后者就是在途中找最大生成树。

# 语义表示(Semantic Representation)

&emsp;&emsp;语义表示在自然语言处理之中是重中之重，很多问题的效果不好就是因为没有能够很有效的表示所有的语义信息。所谓的语义表示就是使用一个向量来表示一个语义单元（词，句子，文章等等）。同一个单元使用不同的学习策略能够学习出不同的语义表示。
