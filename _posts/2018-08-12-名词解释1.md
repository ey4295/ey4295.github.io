---
layout:     post
title:      名词解释1
subtitle:   名词解释1
date:       2018-08-12
author:     徐清华
header-img: img/post-bg-ios9-web.jpg
catalog: 	 true
tags:
    - 自然语言处理
    - 名词解释
---

>本系列的文章将会对一些晦涩难懂的基本概念进行解释。文章侧重点在于使用通俗易懂，简明扼要的语言对这些概念进行说明。这么做的主要目标有两个：①加深对所解释的概念的理解；②提高语言组织，逻辑组织能力

# 1.机器学习

#### 模型

&emsp;&emsp;机器学习官方定义呢是通过算法实现机器在某方面的表现的过程叫做机器学习。这个定义显然很好，很准确，但是却对初学者来说是非常非常没有意义的。

&emsp;&emsp;首先我们从一个最直观的角度来理解。相比你们也听说过，机器学习呢最终的目的就是为了预测。规范一点说就是通过从一堆数据中总结规律，我们可以对未知的情况发展做出预测。根据预测类型的不同呢，机器学习可以简单的分为**分类问题**和**回归问题**。而根据训练数据是否有标签可以分为**有监督**和**无监督**的训练。不同类型的问题呢，将会由不同的方案进行处理，但是我们需要注意的一点是：**无论什么类型的问题，其解决的方案只会从两个大方向出发：生成式和判别式模型**。

&emsp;&emsp;我们举一个简单的例子：红酒和白酒的判别。想象一下这样的场景：假如说你是一名鉴酒师。你的工作呢很简单，就是给你一瓶酒，你观察一下，喝一口，品一下（**特征提取**），然后给老板说这是白酒还是红酒（**预测**）。括号中加粗的两个名词呢就是你干的活了，简单吧。

&emsp;&emsp;现在呢，主要的问题就是怎么让电脑完成这一工作，怎么让电脑和你一样优秀？那么我们就得看看你的工作中比较难模仿的地方在哪里？没错，就是预测。你是凭借什么做出的预测呢？凭借你对酒的了解！你一生阅酒无数，从酒中总结出来了规律。这里我们需要说明一下，在这个世界上鉴酒师还有很多，他们也都总结出来了自己的规律，他们有的只是认识到了最表层的规律，有的则像你一样认识到了最深刻的规律。我们大概呢是可以将这世界上的品酒师分为两种：生成式鉴酒师和判别式鉴酒师。判别式鉴酒师比较菜，他们只会一件事：判别。顾名思义，只要给一瓶酒他们就能告诉你这是什么酒。而生成式鉴酒师可就厉害了，和酒相关的所有事情他都无所不知，无所不晓。无论是判别是什么酒，还是根据酒的类别说出酒的特点他们都能应对的游刃有余。

&emsp;&emsp;好啦，小故事到这里就要告一段落了，我们来看看这里的数学含义都是什么。我们首先给出几个基本概念。我们的鉴酒问题呢，本质上是个分类问题，假设我们从任意一瓶酒中提取出的信息为向量$x=(x_1,x_2,...,x_T)$,该向量包含$T$个特征（特征可以理解为属性，比如说纯度、颜色、甜度等）。那么老板给你的这瓶酒假如说是$x^{now}$，现在的问题就变成了预测酒的品种$y^{now}$。

&emsp;&emsp;判别式模型经过训练之后可以获得任意一瓶酒的条件概率$p(y|x)$，有了这个公式我们只需要把特征向量$x=x^{now}$代入，就能求出来每个类别对应的概率，那么概率最高的就是模型对这瓶酒的预测类别。即

$$y^{now}=arg max_{y \in Y} \{p(y|x=x^{now})\}$$
&emsp;&emsp;常见的判别式模型如下图

![常见判别式模型](https://i.loli.net/2018/08/15/5b73c2a98c198.png)

&emsp;&emsp;生成式模型经过训练之后可以获得酒和酒的品类的所有信息，也就是联合概率分布$p(x,y)$，那么这个时候要是想对问题进行预测的话就只需要利用**贝叶斯公式**，就可以在预测时转化成判别式模型一样的问题。（注意，在预测一个样本的归属时，$x$是固定不变的，所以分母是不变的，因此只要比较分子就可以，而分子就是生成式模型的基本公式，所以一定是已知的）


$$p(y|x)=\frac{p(x,y)}{p(x)}$$

&emsp;&emsp;常见的生成式模型如下图

![常见生成式模型](https://i.loli.net/2018/08/15/5b73c25c2d7c9.png)

&emsp;&emsp;讲到这里，我们不得不额外提到另外一种模型——生成函数模型。从前面的介绍中我们可以看出，生成式模型学的东西最多，判别式模型学的东西有所减少但是仍然足够用来做分类。并且无论是生成式还是判别式在做预测的时候都是通过比较各个分类标签的概率得到的最有可能的预测结果。而生成函数模型呢，则是采用了一种更加简洁明了的方式——直接对类别的分界线建模。我们想想一下，这样建立起来的模型，不可能对酒和类别标签的分布有着深入的认识，甚至说对酒本身的概率分布也是认识不足的，它能做的就是把酒分类，仅此而已。该模型的基本形式是

$$y=f(x)$$

#### 训练

&emsp;&emsp;前面介绍了三种基本模型，可以说有了这些模型我们就能做出预测了。但是问题就在于，这些模型怎么得到？其实确定这些模型，就是指的确定这些模型的参数，而确定模型参数就是利用手头上已经有的数据总结规律，选择最适合的一套参数，而这样的过程就是**模型的训练**。

&emsp;&emsp;模型的训练过程其实并不复杂，无论是判别式、生成式还是生成函数式，都会用一个式子来表示模型。

$$p(y|x)$$
$$p(x,y)$$
$$y=f(x)$$

&emsp;&emsp;可以说，无论是哪一种，我们采取的措施是一样的。

&emsp;&emsp;1.**做出假设**。简单来说，就是给模型一个具体的形式。比如说我们假设$y=f(x)=w_0+w_1x_1+w_2x_2+...+w_nx_n$

&emsp;&emsp;2.**搜索假设空间，选择最优参数**。想一想，我们要选择最优的参数，最简单的办法就是遍历参数空间里所有可能的组合。但是，我们也能看出这样做的代价太大。所以存在着一系列的方法能够帮助我们更快更高效的选择最适合的参数，而这些方法呢就是**优化方法**，包括梯度下降等各种方法。

#### 预测

&emsp;&emsp;有了训练好的模型，预测问题就变得水到渠成了。我们只需要把待预测的样本输入到模型当中，就能够根据不同的预测机制对该样本的结果进行预测。这里也就不再多说了。

---

# 神经网络

&emsp;&emsp;神经网络，英文全称是Atificial Neural Network，即人工神经网络。这个名字起的其实是不负责任的，因为两者之间千差万别。之所以叫这个名字是因为人工神经网络从人类神经网络中借鉴了一些观点，注意只是一些。

&emsp;&emsp;那么我们来看神经网络模型的提出。没错，我说是模型。神经网络就是前面提到的机器学习的模型部分替换成了神经网络。那么为什么要替换呢？答案很简单，就是原来的模型太简单，只能对简单的任务进行处理，遇到复杂的任务就麻了爪了。那么什么是简单什么是复杂呢？我们来看一下第一段中提出的
# 深度学习

# 自然语言处理

# 词向量（Embeddings）

# 指代消歧(Coreference Resolution)
